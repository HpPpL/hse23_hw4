{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujPKQtQqAXU4"
      },
      "source": [
        "ДЗ за день до дедлайна? Классика.\n",
        "\n",
        "Начнем с условий!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCsxlCriA_dK"
      },
      "source": [
        "# Домашнее задание №4\n",
        "\n",
        "# Введение\n",
        "\n",
        "Целью данного задания является сравнение RNA-seq данных перепрограммированных и неперепрограммированных (контрольных) мышиных эмбриональных фибробластов (MEFs) и нахождение генов, которые наиболее сильно изменяют свою экспрессию в этом процессе.\n",
        "\n",
        "# Обязательная часть задания (8 баллов)\n",
        "\n",
        "- На сайте github.com создаем **приватный** репозиторий «hse23\\_hw4» и приводим ссылку на этот репозиторий в общей гугл-таблице ( **вкладка HW4** ) [https://docs.google.com/spreadsheets/d/1HItcZ\\_5Z4ETo9M5MsVOE3gqNPdFEWLsyM6j1t09fwec/edit?usp=sharing](https://docs.google.com/spreadsheets/d/1HItcZ_5Z4ETo9M5MsVOE3gqNPdFEWLsyM6j1t09fwec/edit?usp=sharing)\n",
        "  - Также необходимо дать доступ ассистенту к репозиторию для будущей проверки (Settings =\\> Collaborators =\\> Add people):\n",
        "![](RackMultipart20231125-1-xkm74j_html_7563f38078fb9535.png)\n",
        "- Рекомендуется выполнять работу в Google Colab ноутбуках.\n",
        "  - Если вы будете выполнять работу на сервере или на своем компьютере, необходимо будет также загрузить написанный код на Github\n",
        "- В данном задании будут проанализированы следующие 6 RNA-seq образцов:\n",
        "  - Перепрограммированные образцы: SRR3414629, SRR3414630, SRR3414631\n",
        "  - Контрольные образцы: SRR3414635, SRR3414636, SRR3414637\n",
        "- Выравнивание RNA-seq чтений на геном мыши:\n",
        "  - Пример Google Colab ноутбука с примерами запуска только для одного файла (образца). **Вам следует сделать это для всех 6-ти файлов**.\n",
        "  - [https://colab.research.google.com/drive/120VEu4Rzv0qVRMsNH-Fy86hG0YjvORpJ?usp=sharing](https://colab.research.google.com/drive/120VEu4Rzv0qVRMsNH-Fy86hG0YjvORpJ?usp=sharing)\n",
        "  - Результатом этой части задания будет сводная таблица ALL.counts, где указано кол-во чтений уникально картированных на каждый ген в каждом образце следующего вида:\n",
        "\n",
        "![](RackMultipart20231125-1-xkm74j_html_c0c6351ebd1fae3.png)\n",
        "\n",
        "# Бонусная часть задания 1 (2 балла)\n",
        "\n",
        "- Поиск генов, которые значимо поменяли свою экспрессию (дифференциально-экспрессированные гены) в результате перепрограммирования с помощью R-пакета DESeq2\n",
        "  - Пример Google Colab ноутбука на R [https://colab.research.google.com/drive/1OAlyTlVFBCllorI9mBfgj0Avg76ZHNJK?usp=sharing](https://colab.research.google.com/drive/1OAlyTlVFBCllorI9mBfgj0Avg76ZHNJK?usp=sharing)\n",
        "  - Для этой части задания потребуется файл ALL.counts (созданный выше), а также небольшой файл ALL.info с информацией по каждому образцу следующего вида\n",
        "\n",
        "![](RackMultipart20231125-1-xkm74j_html_d94c0c254c944eb9.png)\n",
        "\n",
        "# Список файлов для сдачи\n",
        "\n",
        "- В репозитории в файле _README_.md\n",
        "  - Ссылки на google colab ноутбуки\n",
        "  - Скриншоты и статистика из файлов FastQC или multiQC\n",
        "  - Таблицу со статистикой по каждому из 6-ти образцов:\n",
        "    - ID образца\n",
        "    - Тип образца (перепрограммированние или контроль)\n",
        "    - Общее кол-во исходных чтений\n",
        "    - Кол-во и процент чтений, которые были успешно откартированы на геном (уникально или нет)\n",
        "    - Кол-во и процент уникально откартированных чтений\n",
        "    - Общее кол-во чтений, которые попали на гены\n",
        "  - Графики из анализа DESeq2 (бонус)\n",
        "    - MA-plot\n",
        "    - Тепловая карта, которая показывает, что все контрольные образцы похожи между собой, а перепрограммированные образцы -- между собой\n",
        "    - Для нескольких генов, которые наиболее значимо поменяли свою экспрессию -- графики со значениями \"Normalized counts\" в контрольных и перепрограммированных образцах\n",
        "- В репозитории в папке data\n",
        "  - Файл ALL.counts -- сводная таблица, где указано кол-во чтений уникально картированных на каждый ген в каждом образце\n",
        "  - Файл differentially\\_expressed\\_genes.txt -- результат работы DESeq2 для всех генов\n",
        "- В репозитории в папке src – любой другой код, который был использован для выполнения задания\n",
        "\n",
        "# Форма отчетности\n",
        "\n",
        "Github репозиторий, содержащий все полученные результаты.\n",
        "\n",
        "**Последний срок сдачи: 26 ноября до 23:59 (будет отслеживаться по последнему коммиту в репозиторий).**\n",
        "\n",
        "**В случае возникновения вопросов пишите на Telegram ассистента (или в общий чат курса).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rFZS5A_yy1o"
      },
      "source": [
        "# Подготовка файлов и программ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DFpK_Pf1hAX"
      },
      "source": [
        "## Установка HISAT2 (для выравниваия RNA-seq чтений на геном)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS21uIX63ehw",
        "outputId": "64fa857c-0ab1-496c-c9be-81441213c281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,016 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,244 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,520 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,242 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,152 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,284 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,498 kB]\n",
            "Fetched 10.2 MB in 4s (2,787 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  bcftools libhts3 libhtscodecs2 python3-hisat2 samtools\n",
            "Suggested packages:\n",
            "  python3-numpy python3-matplotlib texlive-latex-recommended cwltool\n",
            "The following NEW packages will be installed:\n",
            "  bcftools hisat2 libhts3 libhtscodecs2 python3-hisat2 samtools\n",
            "0 upgraded, 6 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 5,505 kB of archives.\n",
            "After this operation, 17.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhtscodecs2 amd64 1.1.1-3 [53.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhts3 amd64 1.13+ds-2build1 [390 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 bcftools amd64 1.13-1 [697 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 hisat2 amd64 2.2.1-3 [3,832 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-hisat2 all 2.2.1-3 [12.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 samtools amd64 1.13-4 [520 kB]\n",
            "Fetched 5,505 kB in 3s (2,120 kB/s)\n",
            "Selecting previously unselected package libhtscodecs2:amd64.\n",
            "(Reading database ... 120880 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libhtscodecs2_1.1.1-3_amd64.deb ...\n",
            "Unpacking libhtscodecs2:amd64 (1.1.1-3) ...\n",
            "Selecting previously unselected package libhts3:amd64.\n",
            "Preparing to unpack .../1-libhts3_1.13+ds-2build1_amd64.deb ...\n",
            "Unpacking libhts3:amd64 (1.13+ds-2build1) ...\n",
            "Selecting previously unselected package bcftools.\n",
            "Preparing to unpack .../2-bcftools_1.13-1_amd64.deb ...\n",
            "Unpacking bcftools (1.13-1) ...\n",
            "Selecting previously unselected package hisat2.\n",
            "Preparing to unpack .../3-hisat2_2.2.1-3_amd64.deb ...\n",
            "Unpacking hisat2 (2.2.1-3) ...\n",
            "Selecting previously unselected package python3-hisat2.\n",
            "Preparing to unpack .../4-python3-hisat2_2.2.1-3_all.deb ...\n",
            "Unpacking python3-hisat2 (2.2.1-3) ...\n",
            "Selecting previously unselected package samtools.\n",
            "Preparing to unpack .../5-samtools_1.13-4_amd64.deb ...\n",
            "Unpacking samtools (1.13-4) ...\n",
            "Setting up libhtscodecs2:amd64 (1.1.1-3) ...\n",
            "Setting up libhts3:amd64 (1.13+ds-2build1) ...\n",
            "Setting up bcftools (1.13-1) ...\n",
            "Setting up samtools (1.13-4) ...\n",
            "Setting up hisat2 (2.2.1-3) ...\n",
            "Setting up python3-hisat2 (2.2.1-3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/usr/bin/hisat2-align-s version 2.2.1\n",
            "64-bit\n",
            "Built on Debian\n",
            "28 September 2021\n",
            "Compiler: gcc version 11.2.0 (Ubuntu 11.2.0-7ubuntu2) \n",
            "Options: -O3   -funroll-loops -g3 -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++11\n",
            "Sizeof {int, long, long long, void*, size_t, off_t}: {4, 8, 8, 8, 8, 8}\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install hisat2\n",
        "!hisat2 --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fTXUIiw2WGQ"
      },
      "source": [
        "## Установка sra-toolkit (для скачивания .fastq файлов из NCBI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m-7wf_x2Yue",
        "outputId": "068c9352-1157-4d66-8816-78c8228a60ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  blends-common libkdf5-2 libncbi-vdb2 libncbi-wvdb2 med-config menu\n",
            "Suggested packages:\n",
            "  blends-doc menu-l10n gksu | kde-runtime | ktsuss\n",
            "The following NEW packages will be installed:\n",
            "  blends-common libkdf5-2 libncbi-vdb2 libncbi-wvdb2 med-config menu sra-toolkit\n",
            "0 upgraded, 7 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 8,290 kB of archives.\n",
            "After this operation, 23.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 menu amd64 2.1.47ubuntu4 [354 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 blends-common all 0.7.4ubuntu1 [15.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libkdf5-2 amd64 2.11.2+dfsg-4build2 [14.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libncbi-vdb2 amd64 2.11.2+dfsg-4build2 [1,364 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libncbi-wvdb2 amd64 2.11.2+dfsg-4build2 [1,252 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 sra-toolkit amd64 2.11.3+dfsg-1ubuntu1 [5,277 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 med-config all 3.7.1 [11.6 kB]\n",
            "Fetched 8,290 kB in 3s (2,827 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package menu.\n",
            "(Reading database ... 121080 files and directories currently installed.)\n",
            "Preparing to unpack .../0-menu_2.1.47ubuntu4_amd64.deb ...\n",
            "Unpacking menu (2.1.47ubuntu4) ...\n",
            "Selecting previously unselected package blends-common.\n",
            "Preparing to unpack .../1-blends-common_0.7.4ubuntu1_all.deb ...\n",
            "Unpacking blends-common (0.7.4ubuntu1) ...\n",
            "Selecting previously unselected package libkdf5-2.\n",
            "Preparing to unpack .../2-libkdf5-2_2.11.2+dfsg-4build2_amd64.deb ...\n",
            "Unpacking libkdf5-2 (2.11.2+dfsg-4build2) ...\n",
            "Selecting previously unselected package libncbi-vdb2.\n",
            "Preparing to unpack .../3-libncbi-vdb2_2.11.2+dfsg-4build2_amd64.deb ...\n",
            "Unpacking libncbi-vdb2 (2.11.2+dfsg-4build2) ...\n",
            "Selecting previously unselected package libncbi-wvdb2.\n",
            "Preparing to unpack .../4-libncbi-wvdb2_2.11.2+dfsg-4build2_amd64.deb ...\n",
            "Unpacking libncbi-wvdb2 (2.11.2+dfsg-4build2) ...\n",
            "Selecting previously unselected package sra-toolkit.\n",
            "Preparing to unpack .../5-sra-toolkit_2.11.3+dfsg-1ubuntu1_amd64.deb ...\n",
            "Unpacking sra-toolkit (2.11.3+dfsg-1ubuntu1) ...\n",
            "Selecting previously unselected package med-config.\n",
            "Preparing to unpack .../6-med-config_3.7.1_all.deb ...\n",
            "Unpacking med-config (3.7.1) ...\n",
            "Setting up libncbi-vdb2 (2.11.2+dfsg-4build2) ...\n",
            "Setting up libkdf5-2 (2.11.2+dfsg-4build2) ...\n",
            "Setting up libncbi-wvdb2 (2.11.2+dfsg-4build2) ...\n",
            "Setting up menu (2.1.47ubuntu4) ...\n",
            "Setting up blends-common (0.7.4ubuntu1) ...\n",
            "Setting up sra-toolkit (2.11.3+dfsg-1ubuntu1) ...\n",
            "Setting up med-config (3.7.1) ...\n",
            "Adding group `med' (GID 107) ...\n",
            "Done.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for menu (2.1.47ubuntu4) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install sra-toolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiVlP4mfy74q"
      },
      "source": [
        "## Установка FastQC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62l1Q2ymbENA",
        "outputId": "2690d55d-5ccb-4300-9626-a6c76e3071eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.20.1\" 2023-08-24\n",
            "OpenJDK Runtime Environment (build 11.0.20.1+1-post-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.20.1+1-post-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
            "--2023-11-26 07:30:30--  https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip\n",
            "Resolving www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)... 149.155.133.4\n",
            "Connecting to www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)|149.155.133.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10249221 (9.8M) [application/zip]\n",
            "Saving to: ‘fastqc_v0.11.9.zip’\n",
            "\n",
            "fastqc_v0.11.9.zip  100%[===================>]   9.77M  4.27MB/s    in 2.3s    \n",
            "\n",
            "2023-11-26 07:30:34 (4.27 MB/s) - ‘fastqc_v0.11.9.zip’ saved [10249221/10249221]\n",
            "\n",
            "Archive:  fastqc_v0.11.9.zip\n",
            "  inflating: FastQC/cisd-jhdf5.jar   \n",
            "   creating: FastQC/Configuration/\n",
            "  inflating: FastQC/Configuration/adapter_list.txt  \n",
            "  inflating: FastQC/Configuration/contaminant_list.txt  \n",
            "  inflating: FastQC/Configuration/limits.txt  \n",
            "  inflating: FastQC/fastqc           \n",
            "  inflating: FastQC/fastqc_icon.ico  \n",
            "   creating: FastQC/Help/\n",
            "   creating: FastQC/Help/1 Introduction/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/\n",
            "  inflating: FastQC/Help/1 Introduction/.svn/entries  \n",
            "   creating: FastQC/Help/1 Introduction/.svn/props/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/text-base/\n",
            "  inflating: FastQC/Help/1 Introduction/.svn/text-base/1.1 What is FastQC.html.svn-base  \n",
            "   creating: FastQC/Help/1 Introduction/.svn/tmp/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/1 Introduction/1.1 What is FastQC.html  \n",
            "   creating: FastQC/Help/2 Basic Operations/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/\n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/entries  \n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/props/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/text-base/\n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.1 Opening a sequence file.html.svn-base  \n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.2 Evaluating Results.html.svn-base  \n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.3 Saving a Report.html.svn-base  \n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/2 Basic Operations/2.1 Opening a sequence file.html  \n",
            "  inflating: FastQC/Help/2 Basic Operations/2.2 Evaluating Results.html  \n",
            "  inflating: FastQC/Help/2 Basic Operations/2.3 Saving a Report.html  \n",
            "   creating: FastQC/Help/3 Analysis Modules/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/entries  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/prop-base/\n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/duplication_levels.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/prop-base/kmer_profiles.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_gc_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_n_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_sequence_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_gc_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_tile_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/sequence_length_distribution.png.svn-base  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/props/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/text-base/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/1 Basic Statistics.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/10 Adapter Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/11 Kmer Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/12 Per Tile Sequence Quality.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/2 Per Base Sequence Quality.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/3 Per Sequence Quality Scores.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/4 Per Base Sequence Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/5 Per Sequence GC Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/6 Per Base N Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/7 Sequence Length Distribution.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/8 Duplicate Sequences.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/9 Overrepresented Sequences.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/duplication_levels.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/kmer_profiles.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_gc_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_n_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_sequence_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_gc_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_tile_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/sequence_length_distribution.png.svn-base  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/1 Basic Statistics.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/10 Adapter Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/11 Kmer Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/12 Per Tile Sequence Quality.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/2 Per Base Sequence Quality.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/3 Per Sequence Quality Scores.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/4 Per Base Sequence Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/5 Per Sequence GC Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/6 Per Base N Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/7 Sequence Length Distribution.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/8 Duplicate Sequences.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/9 Overrepresented Sequences.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/duplication_levels.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/kmer_profiles.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_gc_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_n_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_sequence_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_gc_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_tile_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/sequence_length_distribution.png  \n",
            "  inflating: FastQC/INSTALL.txt      \n",
            "  inflating: FastQC/jbzip2-0.9.jar   \n",
            "  inflating: FastQC/LICENSE          \n",
            "  inflating: FastQC/LICENSE.txt      \n",
            "  inflating: FastQC/LICENSE_JHDF5.txt  \n",
            "   creating: FastQC/net/\n",
            "   creating: FastQC/net/sourceforge/\n",
            "   creating: FastQC/net/sourceforge/iharder/\n",
            "   creating: FastQC/net/sourceforge/iharder/base64/\n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$1.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$InputStream.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$OutputStream.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64.class  \n",
            "   creating: FastQC/org/\n",
            "   creating: FastQC/org/apache/\n",
            "   creating: FastQC/org/apache/commons/\n",
            "   creating: FastQC/org/apache/commons/math3/\n",
            "   creating: FastQC/org/apache/commons/math3/analysis/\n",
            "   creating: FastQC/org/apache/commons/math3/analysis/solvers/\n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AbstractUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AllowedSolution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseAbstractUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BracketedUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BrentSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolverUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/UnivariateFunction.class  \n",
            "   creating: FastQC/org/apache/commons/math3/distribution/\n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractIntegerDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/BetaDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/BinomialDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/CauchyDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/ChiSquaredDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/FDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/GammaDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/HypergeometricDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/IntegerDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/NormalDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/PascalDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/PoissonDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/RealDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/SaddlePointExpansion.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/TDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/WeibullDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/ZipfDistribution.class  \n",
            "   creating: FastQC/org/apache/commons/math3/exception/\n",
            "  inflating: FastQC/org/apache/commons/math3/exception/ConvergenceException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/DimensionMismatchException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathArithmeticException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalArgumentException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalNumberException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalStateException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathInternalError.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MaxCountExceededException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NoBracketingException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotFiniteNumberException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotPositiveException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotStrictlyPositiveException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NullArgumentException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooLargeException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooSmallException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/OutOfRangeException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/TooManyEvaluationsException.class  \n",
            "   creating: FastQC/org/apache/commons/math3/exception/util/\n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ArgUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContext.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContextProvider.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/Localizable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/LocalizedFormats.class  \n",
            "   creating: FastQC/org/apache/commons/math3/random/\n",
            "  inflating: FastQC/org/apache/commons/math3/random/AbstractWell.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/BitsStreamGenerator.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomData.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomDataImpl.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomGenerator.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/Well19937c.class  \n",
            "   creating: FastQC/org/apache/commons/math3/special/\n",
            "  inflating: FastQC/org/apache/commons/math3/special/Beta$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Beta.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Erf.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Gamma$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Gamma.class  \n",
            "   creating: FastQC/org/apache/commons/math3/util/\n",
            "  inflating: FastQC/org/apache/commons/math3/util/ArithmeticUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/ContinuedFraction.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/DoubleArray.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpFracTable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpIntTable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$lnMant.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMathCalc.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMathLiteralArrays.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$MaxCountExceededCallback.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/MathUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Precision.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/ResizableDoubleArray.class  \n",
            "  inflating: FastQC/README.md        \n",
            "  inflating: FastQC/README.txt       \n",
            "  inflating: FastQC/RELEASE_NOTES.txt  \n",
            "  inflating: FastQC/run_fastqc.bat   \n",
            "  inflating: FastQC/sam-1.103.jar    \n",
            "   creating: FastQC/Templates/\n",
            "  inflating: FastQC/Templates/fastqc2fo.xsl  \n",
            "  inflating: FastQC/Templates/header_template.html  \n",
            "   creating: FastQC/Templates/Icons/\n",
            " extracting: FastQC/Templates/Icons/error.png  \n",
            " extracting: FastQC/Templates/Icons/fastqc_icon.png  \n",
            " extracting: FastQC/Templates/Icons/tick.png  \n",
            " extracting: FastQC/Templates/Icons/warning.png  \n",
            "   creating: FastQC/uk/\n",
            "   creating: FastQC/uk/ac/\n",
            "   creating: FastQC/uk/ac/babraham/\n",
            "   creating: FastQC/uk/ac/babraham/FastQC/\n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Analysis/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisListener.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisQueue.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisRunner.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/OfflineRunner.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Dialogs/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog$1.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel$SmoothJLabel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/WelcomePanel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication$1.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCConfig.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCMenuBar.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/FileFilters/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/BAMFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/CasavaFastQFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/FastQFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/GobyFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/MappedBAMFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/SequenceFileFilter.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Graphs/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/BaseGroup.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/LineGraph.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/QualityBoxPlot.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/TileGraph.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Help/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpDialog.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot$FileSorter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPage.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay$HelpEditor.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpSearchPanel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Modules/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AbstractQCModule.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$Adapter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/DuplicationLevel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModelValue.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$Kmer.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleConfig.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleFactory.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/NContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$OverrepresentedSeq.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseSequenceContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceGCContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerTileQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/QCModule.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/SequenceLengthDistribution.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Report/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Report/HTMLReportArchive.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Report/stylesheet.txt  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Resources/\n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/error.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.png  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.svg  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon_100.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/tick.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/warning.png  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Results/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel$ModuleRenderer.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/BAMFile.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/Contaminant.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminantHit.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminentFinder.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Fast5File.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/FastQFile.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/PhredEncoding.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Sequence.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFactory.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFile.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFileGroup.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFormatException.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Statistics/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/NormalDistribution.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/PearsonCorrelation.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Utilities/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/CasavaBasename.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/HotColdColourGradient.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/ImageToBase64.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/MultiMemberGZIPInputStream.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NameFormatException.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NanoporeBasename.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/QualityCount.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/RGB.class  \n",
            "\n",
            "            FastQC - A high throughput sequence QC analysis tool\n",
            "\n",
            "SYNOPSIS\n",
            "\n",
            "\tfastqc seqfile1 seqfile2 .. seqfileN\n",
            "\n",
            "    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] \n",
            "           [-c contaminant file] seqfile1 .. seqfileN\n",
            "\n",
            "DESCRIPTION\n",
            "\n",
            "    FastQC reads a set of sequence files and produces from each one a quality\n",
            "    control report consisting of a number of different modules, each one of \n",
            "    which will help to identify a different potential type of problem in your\n",
            "    data.\n",
            "    \n",
            "    If no files to process are specified on the command line then the program\n",
            "    will start as an interactive graphical application.  If files are provided\n",
            "    on the command line then the program will run with no user interaction\n",
            "    required.  In this mode it is suitable for inclusion into a standardised\n",
            "    analysis pipeline.\n",
            "    \n",
            "    The options for the program as as follows:\n",
            "    \n",
            "    -h --help       Print this help file and exit\n",
            "    \n",
            "    -v --version    Print the version of the program and exit\n",
            "    \n",
            "    -o --outdir     Create all output files in the specified output directory.\n",
            "                    Please note that this directory must exist as the program\n",
            "                    will not create it.  If this option is not set then the \n",
            "                    output file for each sequence file is created in the same\n",
            "                    directory as the sequence file which was processed.\n",
            "                    \n",
            "    --casava        Files come from raw casava output. Files in the same sample\n",
            "                    group (differing only by the group number) will be analysed\n",
            "                    as a set rather than individually. Sequences with the filter\n",
            "                    flag set in the header will be excluded from the analysis.\n",
            "                    Files must have the same names given to them by casava\n",
            "                    (including being gzipped and ending with .gz) otherwise they\n",
            "                    won't be grouped together correctly.\n",
            "                    \n",
            "    --nano          Files come from nanopore sequences and are in fast5 format. In\n",
            "                    this mode you can pass in directories to process and the program\n",
            "                    will take in all fast5 files within those directories and produce\n",
            "                    a single output file from the sequences found in all files.                    \n",
            "                    \n",
            "    --nofilter      If running with --casava then don't remove read flagged by\n",
            "                    casava as poor quality when performing the QC analysis.\n",
            "                   \n",
            "    --extract       If set then the zipped output file will be uncompressed in\n",
            "                    the same directory after it has been created.  By default\n",
            "                    this option will be set if fastqc is run in non-interactive\n",
            "                    mode.\n",
            "                    \n",
            "    -j --java       Provides the full path to the java binary you want to use to\n",
            "                    launch fastqc. If not supplied then java is assumed to be in\n",
            "                    your path.\n",
            "                   \n",
            "    --noextract     Do not uncompress the output file after creating it.  You\n",
            "                    should set this option if you do not wish to uncompress\n",
            "                    the output when running in non-interactive mode.\n",
            "                    \n",
            "    --nogroup       Disable grouping of bases for reads >50bp. All reports will\n",
            "                    show data for every base in the read.  WARNING: Using this\n",
            "                    option will cause fastqc to crash and burn if you use it on\n",
            "                    really long reads, and your plots may end up a ridiculous size.\n",
            "                    You have been warned!\n",
            "                    \n",
            "    --min_length    Sets an artificial lower limit on the length of the sequence\n",
            "                    to be shown in the report.  As long as you set this to a value\n",
            "                    greater or equal to your longest read length then this will be\n",
            "                    the sequence length used to create your read groups.  This can\n",
            "                    be useful for making directly comaparable statistics from \n",
            "                    datasets with somewhat variable read lengths.\n",
            "                    \n",
            "    -f --format     Bypasses the normal sequence file format detection and\n",
            "                    forces the program to use the specified format.  Valid\n",
            "                    formats are bam,sam,bam_mapped,sam_mapped and fastq\n",
            "                    \n",
            "    -t --threads    Specifies the number of files which can be processed\n",
            "                    simultaneously.  Each thread will be allocated 250MB of\n",
            "                    memory so you shouldn't run more threads than your\n",
            "                    available memory will cope with, and not more than\n",
            "                    6 threads on a 32 bit machine\n",
            "                  \n",
            "    -c              Specifies a non-default file which contains the list of\n",
            "    --contaminants  contaminants to screen overrepresented sequences against.\n",
            "                    The file must contain sets of named contaminants in the\n",
            "                    form name[tab]sequence.  Lines prefixed with a hash will\n",
            "                    be ignored.\n",
            "\n",
            "    -a              Specifies a non-default file which contains the list of\n",
            "    --adapters      adapter sequences which will be explicity searched against\n",
            "                    the library. The file must contain sets of named adapters\n",
            "                    in the form name[tab]sequence.  Lines prefixed with a hash\n",
            "                    will be ignored.\n",
            "                    \n",
            "    -l              Specifies a non-default file which contains a set of criteria\n",
            "    --limits        which will be used to determine the warn/error limits for the\n",
            "                    various modules.  This file can also be used to selectively \n",
            "                    remove some modules from the output all together.  The format\n",
            "                    needs to mirror the default limits.txt file found in the\n",
            "                    Configuration folder.\n",
            "                    \n",
            "   -k --kmers       Specifies the length of Kmer to look for in the Kmer content\n",
            "                    module. Specified Kmer length must be between 2 and 10. Default\n",
            "                    length is 7 if not specified.\n",
            "                    \n",
            "   -q --quiet       Supress all progress messages on stdout and only report errors.\n",
            "   \n",
            "   -d --dir         Selects a directory to be used for temporary files written when\n",
            "                    generating report images. Defaults to system temp directory if\n",
            "                    not specified.\n",
            "                    \n",
            "BUGS\n",
            "\n",
            "    Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk\n",
            "    or in www.bioinformatics.babraham.ac.uk/bugzilla/\n",
            "                   \n",
            "    \n"
          ]
        }
      ],
      "source": [
        "!java -version\n",
        "!wget https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip\n",
        "!unzip fastqc_v0.11.9.zip\n",
        "!chmod a+x FastQC/fastqc\n",
        "!./FastQC/fastqc --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dqWpZZ_0_V-"
      },
      "source": [
        "## Установка HTSeq-count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_yqggdMhMfj",
        "outputId": "d4de629c-7fee-4012-de66-ae2e7ee1372a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting HTSeq\n",
            "  Downloading HTSeq-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from HTSeq) (1.23.5)\n",
            "Collecting pysam (from HTSeq)\n",
            "  Downloading pysam-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (21.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.9/21.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pysam, HTSeq\n",
            "Successfully installed HTSeq-2.0.4 pysam-0.22.0\n",
            "2.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install HTSeq\n",
        "!htseq-count --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRYVC5z_DYqS"
      },
      "source": [
        "## Установка MultiQC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtpnPGb9DeX3",
        "outputId": "7e89c276-bc79-407b-f40f-c5b0cb3de7cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting multiqc\n",
            "  Downloading multiqc-1.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from multiqc) (3.7.1)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from multiqc) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from multiqc) (1.23.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from multiqc) (8.1.7)\n",
            "Collecting coloredlogs (from multiqc)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future>0.14.0 in /usr/local/lib/python3.10/dist-packages (from multiqc) (0.18.3)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from multiqc) (3.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from multiqc) (3.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from multiqc) (23.2)\n",
            "Requirement already satisfied: pyyaml>=4 in /usr/local/lib/python3.10/dist-packages (from multiqc) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from multiqc) (2.31.0)\n",
            "Requirement already satisfied: rich>=10 in /usr/local/lib/python3.10/dist-packages (from multiqc) (13.7.0)\n",
            "Collecting rich-click (from multiqc)\n",
            "  Downloading rich_click-1.7.1-py3-none-any.whl (32 kB)\n",
            "Collecting spectra>=0.0.10 (from multiqc)\n",
            "  Downloading spectra-0.0.11.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from multiqc) (6.8.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from multiqc) (4.7.0)\n",
            "Collecting pyaml-env (from multiqc)\n",
            "  Downloading pyaml_env-1.2.1-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->multiqc) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.1->multiqc) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.1->multiqc) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.1->multiqc) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.1->multiqc) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.1->multiqc) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.1->multiqc) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.1->multiqc) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10->multiqc) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10->multiqc) (2.16.1)\n",
            "Collecting colormath>=3.0.0 (from spectra>=0.0.10->multiqc)\n",
            "  Downloading colormath-3.0.0.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->multiqc)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->multiqc) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->multiqc) (2023.7.22)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from rich-click->multiqc) (4.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10->multiqc) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.1->multiqc) (1.16.0)\n",
            "Building wheels for collected packages: spectra, colormath\n",
            "  Building wheel for spectra (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectra: filename=spectra-0.0.11-py3-none-any.whl size=17467 sha256=6c3df8b5eaf40ec498c2add2ec5fc18ecbac770975272b65142d9e783744e90a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/27/ec/cddaa9489a49ddcf702e1f4dc1791db28a3b0121e1ff254f97\n",
            "  Building wheel for colormath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colormath: filename=colormath-3.0.0-py3-none-any.whl size=39405 sha256=7a3b317ce592e42be04839b48aa2d661a87d8e327e0144c27a0ea04e4c6a629d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b3/4d/c0738759c25a1df01958068f162cf2a9dc3ab1da8b972cfcfc\n",
            "Successfully built spectra colormath\n",
            "Installing collected packages: pyaml-env, humanfriendly, colormath, spectra, coloredlogs, rich-click, multiqc\n",
            "Successfully installed coloredlogs-15.0.1 colormath-3.0.0 humanfriendly-10.0 multiqc-1.18 pyaml-env-1.2.1 rich-click-1.7.1 spectra-0.0.11\n"
          ]
        }
      ],
      "source": [
        "!pip install multiqc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6MhDf5N2tQ3"
      },
      "source": [
        "## Скачиваем RNA-seq данные и выравниваем их"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LicIlxo028wE"
      },
      "source": [
        "* Перепрограммированные образцы: \tSRR3414629, SRR3414630, SRR3414631\n",
        "* Контрольные образцы:\t\tSRR3414635, SRR3414636, SRR3414637"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7-OCZli2z38",
        "outputId": "d681e736-e22b-476a-e3d4-e511c3266aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 21106089 spots for SRR3414629\n",
            "Written 21106089 spots for SRR3414629\n",
            "\n",
            "real\t9m50.174s\n",
            "user\t3m24.699s\n",
            "sys\t0m10.195s\n",
            "Started analysis of SRR3414629_1.fastq\n",
            "Approx 5% complete for SRR3414629_1.fastq\n",
            "Approx 10% complete for SRR3414629_1.fastq\n",
            "Approx 15% complete for SRR3414629_1.fastq\n",
            "Approx 20% complete for SRR3414629_1.fastq\n",
            "Approx 25% complete for SRR3414629_1.fastq\n",
            "Approx 30% complete for SRR3414629_1.fastq\n",
            "Approx 35% complete for SRR3414629_1.fastq\n",
            "Approx 40% complete for SRR3414629_1.fastq\n",
            "Approx 45% complete for SRR3414629_1.fastq\n",
            "Approx 50% complete for SRR3414629_1.fastq\n",
            "Approx 55% complete for SRR3414629_1.fastq\n",
            "Approx 60% complete for SRR3414629_1.fastq\n",
            "Approx 65% complete for SRR3414629_1.fastq\n",
            "Approx 70% complete for SRR3414629_1.fastq\n",
            "Approx 75% complete for SRR3414629_1.fastq\n",
            "Approx 80% complete for SRR3414629_1.fastq\n",
            "Approx 85% complete for SRR3414629_1.fastq\n",
            "Approx 90% complete for SRR3414629_1.fastq\n",
            "Approx 95% complete for SRR3414629_1.fastq\n",
            "Analysis complete for SRR3414629_1.fastq\n",
            "Read 15244711 spots for SRR3414630\n",
            "Written 15244711 spots for SRR3414630\n",
            "\n",
            "real\t7m1.185s\n",
            "user\t2m29.580s\n",
            "sys\t0m7.441s\n",
            "Started analysis of SRR3414630_1.fastq\n",
            "Approx 5% complete for SRR3414630_1.fastq\n",
            "Approx 10% complete for SRR3414630_1.fastq\n",
            "Approx 15% complete for SRR3414630_1.fastq\n",
            "Approx 20% complete for SRR3414630_1.fastq\n",
            "Approx 25% complete for SRR3414630_1.fastq\n",
            "Approx 30% complete for SRR3414630_1.fastq\n",
            "Approx 35% complete for SRR3414630_1.fastq\n",
            "Approx 40% complete for SRR3414630_1.fastq\n",
            "Approx 45% complete for SRR3414630_1.fastq\n",
            "Approx 50% complete for SRR3414630_1.fastq\n",
            "Approx 55% complete for SRR3414630_1.fastq\n",
            "Approx 60% complete for SRR3414630_1.fastq\n",
            "Approx 65% complete for SRR3414630_1.fastq\n",
            "Approx 70% complete for SRR3414630_1.fastq\n",
            "Approx 75% complete for SRR3414630_1.fastq\n",
            "Approx 80% complete for SRR3414630_1.fastq\n",
            "Approx 85% complete for SRR3414630_1.fastq\n",
            "Approx 90% complete for SRR3414630_1.fastq\n",
            "Approx 95% complete for SRR3414630_1.fastq\n",
            "Analysis complete for SRR3414630_1.fastq\n",
            "Read 24244069 spots for SRR3414631\n",
            "Written 24244069 spots for SRR3414631\n",
            "\n",
            "real\t11m18.313s\n",
            "user\t3m58.130s\n",
            "sys\t0m12.290s\n",
            "Started analysis of SRR3414631_1.fastq\n",
            "Approx 5% complete for SRR3414631_1.fastq\n",
            "Approx 10% complete for SRR3414631_1.fastq\n",
            "Approx 15% complete for SRR3414631_1.fastq\n",
            "Approx 20% complete for SRR3414631_1.fastq\n",
            "Approx 25% complete for SRR3414631_1.fastq\n",
            "Approx 30% complete for SRR3414631_1.fastq\n",
            "Approx 35% complete for SRR3414631_1.fastq\n",
            "Approx 40% complete for SRR3414631_1.fastq\n",
            "Approx 45% complete for SRR3414631_1.fastq\n",
            "Approx 50% complete for SRR3414631_1.fastq\n",
            "Approx 55% complete for SRR3414631_1.fastq\n",
            "Approx 60% complete for SRR3414631_1.fastq\n",
            "Approx 65% complete for SRR3414631_1.fastq\n",
            "Approx 70% complete for SRR3414631_1.fastq\n",
            "Approx 75% complete for SRR3414631_1.fastq\n",
            "Approx 80% complete for SRR3414631_1.fastq\n",
            "Approx 85% complete for SRR3414631_1.fastq\n",
            "Approx 90% complete for SRR3414631_1.fastq\n",
            "Approx 95% complete for SRR3414631_1.fastq\n",
            "Analysis complete for SRR3414631_1.fastq\n",
            "Read 20956475 spots for SRR3414635\n",
            "Written 20956475 spots for SRR3414635\n",
            "\n",
            "real\t9m56.726s\n",
            "user\t3m27.800s\n",
            "sys\t0m10.698s\n",
            "Started analysis of SRR3414635_1.fastq\n",
            "Approx 5% complete for SRR3414635_1.fastq\n",
            "Approx 10% complete for SRR3414635_1.fastq\n",
            "Approx 15% complete for SRR3414635_1.fastq\n",
            "Approx 20% complete for SRR3414635_1.fastq\n",
            "Approx 25% complete for SRR3414635_1.fastq\n",
            "Approx 30% complete for SRR3414635_1.fastq\n",
            "Approx 35% complete for SRR3414635_1.fastq\n",
            "Approx 40% complete for SRR3414635_1.fastq\n",
            "Approx 45% complete for SRR3414635_1.fastq\n",
            "Approx 50% complete for SRR3414635_1.fastq\n",
            "Approx 55% complete for SRR3414635_1.fastq\n",
            "Approx 60% complete for SRR3414635_1.fastq\n",
            "Approx 65% complete for SRR3414635_1.fastq\n",
            "Approx 70% complete for SRR3414635_1.fastq\n",
            "Approx 75% complete for SRR3414635_1.fastq\n",
            "Approx 80% complete for SRR3414635_1.fastq\n",
            "Approx 85% complete for SRR3414635_1.fastq\n",
            "Approx 90% complete for SRR3414635_1.fastq\n",
            "Approx 95% complete for SRR3414635_1.fastq\n",
            "Analysis complete for SRR3414635_1.fastq\n",
            "Read 20307147 spots for SRR3414636\n",
            "Written 20307147 spots for SRR3414636\n",
            "\n",
            "real\t9m31.459s\n",
            "user\t3m24.022s\n",
            "sys\t0m11.698s\n",
            "Started analysis of SRR3414636_1.fastq\n",
            "Approx 5% complete for SRR3414636_1.fastq\n",
            "Approx 10% complete for SRR3414636_1.fastq\n",
            "Approx 15% complete for SRR3414636_1.fastq\n",
            "Approx 20% complete for SRR3414636_1.fastq\n",
            "Approx 25% complete for SRR3414636_1.fastq\n",
            "Approx 30% complete for SRR3414636_1.fastq\n",
            "Approx 35% complete for SRR3414636_1.fastq\n",
            "Approx 40% complete for SRR3414636_1.fastq\n",
            "Approx 45% complete for SRR3414636_1.fastq\n",
            "Approx 50% complete for SRR3414636_1.fastq\n",
            "Approx 55% complete for SRR3414636_1.fastq\n",
            "Approx 60% complete for SRR3414636_1.fastq\n",
            "Approx 65% complete for SRR3414636_1.fastq\n",
            "Approx 70% complete for SRR3414636_1.fastq\n",
            "Approx 75% complete for SRR3414636_1.fastq\n",
            "Approx 80% complete for SRR3414636_1.fastq\n",
            "Approx 85% complete for SRR3414636_1.fastq\n",
            "Approx 90% complete for SRR3414636_1.fastq\n",
            "Approx 95% complete for SRR3414636_1.fastq\n",
            "Analysis complete for SRR3414636_1.fastq\n",
            "Read 20385570 spots for SRR3414637\n",
            "Written 20385570 spots for SRR3414637\n",
            "\n",
            "real\t9m48.033s\n",
            "user\t3m22.429s\n",
            "sys\t0m11.456s\n",
            "Started analysis of SRR3414637_1.fastq\n",
            "Approx 5% complete for SRR3414637_1.fastq\n",
            "Approx 10% complete for SRR3414637_1.fastq\n",
            "Approx 15% complete for SRR3414637_1.fastq\n",
            "Approx 20% complete for SRR3414637_1.fastq\n",
            "Approx 25% complete for SRR3414637_1.fastq\n",
            "Approx 30% complete for SRR3414637_1.fastq\n",
            "Approx 35% complete for SRR3414637_1.fastq\n",
            "Approx 40% complete for SRR3414637_1.fastq\n",
            "Approx 45% complete for SRR3414637_1.fastq\n",
            "Approx 50% complete for SRR3414637_1.fastq\n",
            "Approx 55% complete for SRR3414637_1.fastq\n",
            "Approx 60% complete for SRR3414637_1.fastq\n",
            "Approx 65% complete for SRR3414637_1.fastq\n",
            "Approx 70% complete for SRR3414637_1.fastq\n",
            "Approx 75% complete for SRR3414637_1.fastq\n",
            "Approx 80% complete for SRR3414637_1.fastq\n",
            "Approx 85% complete for SRR3414637_1.fastq\n",
            "Approx 90% complete for SRR3414637_1.fastq\n",
            "Approx 95% complete for SRR3414637_1.fastq\n",
            "Analysis complete for SRR3414637_1.fastq\n",
            "\n",
            "  \u001b[91m///\u001b[0m \u001b]8;id=151315;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2m| v1.18\u001b[0m\n",
            "\n",
            "\u001b[34m|           multiqc\u001b[0m | Search path : /content\n",
            "\u001b[2K\u001b[34m|\u001b[0m         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m293/293\u001b[0m  \n",
            "\u001b[?25h\u001b[34m|            fastqc\u001b[0m | Found 6 reports\n",
            "\u001b[34m|           multiqc\u001b[0m | Report      : concatenated_report.html\n",
            "\u001b[34m|           multiqc\u001b[0m | Data        : concatenated_report_data\n",
            "\u001b[34m|           multiqc\u001b[0m | MultiQC complete\n"
          ]
        }
      ],
      "source": [
        "!time  fastq-dump  --split-files  SRR3414629\n",
        "!./FastQC/fastqc  /content/SRR3414629_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414630\n",
        "!./FastQC/fastqc  /content/SRR3414630_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414631\n",
        "!./FastQC/fastqc  /content/SRR3414631_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414635\n",
        "!./FastQC/fastqc  /content/SRR3414635_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414636\n",
        "!./FastQC/fastqc  /content/SRR3414636_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414637\n",
        "!./FastQC/fastqc  /content/SRR3414637_1.fastq\n",
        "\n",
        "!multiqc . --filename concatenated_report.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAn1rivS0BME"
      },
      "source": [
        "## Скачиваем геном мыши mm10 (проиндексированный для HISAT2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWfSQMGZ03Ch",
        "outputId": "930c9a77-9da9-4df3-bcaa-21536ff1a7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-26 08:40:34--  https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz\n",
            "Resolving genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)... 3.5.28.149, 52.217.197.73, 3.5.1.216, ...\n",
            "Connecting to genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)|3.5.28.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3804366597 (3.5G) [binary/octet-stream]\n",
            "Saving to: ‘mm10_genome.tar.gz’\n",
            "\n",
            "mm10_genome.tar.gz  100%[===================>]   3.54G  14.3MB/s    in 4m 27s  \n",
            "\n",
            "2023-11-26 08:45:03 (13.6 MB/s) - ‘mm10_genome.tar.gz’ saved [3804366597/3804366597]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IKaXKp7eLjq",
        "outputId": "e4a6633c-0969-4df2-ce0c-e49999d6de9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm10/\n",
            "mm10/genome.8.ht2\n",
            "mm10/genome.5.ht2\n",
            "mm10/make_mm10.sh\n",
            "mm10/genome.7.ht2\n",
            "mm10/genome.6.ht2\n",
            "mm10/genome.4.ht2\n",
            "mm10/genome.3.ht2\n",
            "mm10/genome.1.ht2\n",
            "mm10/genome.2.ht2\n"
          ]
        }
      ],
      "source": [
        "!tar -xzvf mm10_genome.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGULD5P70tvT"
      },
      "source": [
        "## Скачиваем аннотацию генов GENCODE для генома мыши mm10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8SxMZMC3Aw-",
        "outputId": "c12e387c-ca2f-4cc3-b161-e03684052a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-26 08:45:59--  http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz\n",
            "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.193.165\n",
            "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.193.165|:80... connected.\n",
            "HTTP request sent, awaiting response... Read error (Connection reset by peer) in headers.\n",
            "Retrying.\n",
            "\n",
            "--2023-11-26 08:46:01--  (try: 2)  http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz\n",
            "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.193.165|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28542432 (27M) [application/x-gzip]\n",
            "Saving to: ‘gencode.vM25.annotation.gtf.gz’\n",
            "\n",
            "gencode.vM25.annota 100%[===================>]  27.22M   282KB/s    in 1m 42s  \n",
            "\n",
            "2023-11-26 08:47:43 (273 KB/s) - ‘gencode.vM25.annotation.gtf.gz’ saved [28542432/28542432]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "K9RerBtX8iFF"
      },
      "outputs": [],
      "source": [
        "!gzip -d gencode.vM25.annotation.gtf.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8auHZa11RviG"
      },
      "source": [
        "## Перед отбором чтений скачаем объединенный отчет MultiQC!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "bcQ3dqghR5wb",
        "outputId": "dcf2e753-0b4a-4acf-9477-cf30060ad2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/concatenated_report_data/ (stored 0%)\n",
            "  adding: content/concatenated_report_data/multiqc.log (deflated 65%)\n",
            "  adding: content/concatenated_report_data/multiqc_general_stats.txt (deflated 65%)\n",
            "  adding: content/concatenated_report_data/multiqc_sources.txt (deflated 71%)\n",
            "  adding: content/concatenated_report_data/multiqc_data.json (deflated 92%)\n",
            "  adding: content/concatenated_report_data/multiqc_fastqc.txt (deflated 71%)\n",
            "  adding: content/concatenated_report_data/multiqc_citations.txt (deflated 29%)\n",
            "  adding: content/concatenated_report_data/multiqc_software_versions.txt (deflated 11%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_45b8ab7f-a6ac-4532-b442-86b7bed79784\", \"concatenated_report_data.zip\", 33214)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bde166a5-2526-414b-bbbb-441b5094152a\", \"concatenated_report.html\", 1341062)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r /content/concatenated_report_data.zip /content/concatenated_report_data\n",
        "files.download('concatenated_report_data.zip')\n",
        "files.download('concatenated_report.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzucvMQkzzs9"
      },
      "source": [
        "# Отбор чтений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef5GXLUJTPTK"
      },
      "source": [
        "## При помощи HISAT2 будем картировать чтения на геном мыши. После чего отбираем чтения, которые откартировались уникально!\n",
        "\n",
        "После картирования можно удалить файлы .hisat, .fastq, .sam так как они не нужны более, а месту на диске плохо(\n",
        "\n",
        "  ![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLGDcIxxT4OG",
        "outputId": "46a6c916-d03f-4986-a1d2-bc5e42b14aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t15m35.460s\n",
            "user\t23m0.764s\n",
            "sys\t1m42.652s\n",
            "removed 'SRR3414629_1.sam'\n",
            "18573565\n"
          ]
        }
      ],
      "source": [
        "# Картируем чтения\n",
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414629_1.fastq -S SRR3414629_1.sam  2>  SRR3414629.hisat\n",
        "# Отбираем уникальные чтения\n",
        "!grep -P '^@|NH:i:1$' SRR3414629_1.sam > SRR3414629.uniq.sam\n",
        "# Удаляем исходные .sam файлы\n",
        "!rm -v SRR3414629_1.sam\n",
        "# Считаем кол-во уникально-картированных чтений\n",
        "!grep -v '^@' SRR3414629.uniq.sam | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DBj21nRUXU2",
        "outputId": "ec170de1-8d4f-4884-a76d-edeb0b131c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21106089 reads; of these:\n",
            "  21106089 (100.00%) were unpaired; of these:\n",
            "    241118 (1.14%) aligned 0 times\n",
            "    18573565 (88.00%) aligned exactly 1 time\n",
            "    2291406 (10.86%) aligned >1 times\n",
            "98.86% overall alignment rate\n"
          ]
        }
      ],
      "source": [
        "# Удаляем .hisat и .fastq\n",
        "!cat SRR3414629.hisat\n",
        "!rm SRR3414629.hisat\n",
        "!rm SRR3414629_1.fastq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaK9ojXGUdJ5"
      },
      "source": [
        "## Аналогичные действия проделываем для остальных образцов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_zEQWjeUp05"
      },
      "source": [
        "## SRR3414630:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khl89ruAU6cb",
        "outputId": "63bc7da9-619f-4b00-c0ba-7320d4aefaab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t11m16.214s\n",
            "user\t16m30.218s\n",
            "sys\t1m14.022s\n",
            "removed 'SRR3414630_1.sam'\n",
            "13320505\n"
          ]
        }
      ],
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414630_1.fastq -S SRR3414630_1.sam  2>  SRR3414630.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414630_1.sam > SRR3414630.uniq.sam\n",
        "!rm -v SRR3414630_1.sam\n",
        "!grep -v '^@' SRR3414630.uniq.sam | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5ilxmZOU7mO",
        "outputId": "e50a1918-890e-48bd-d3f0-5142518131b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15244711 reads; of these:\n",
            "  15244711 (100.00%) were unpaired; of these:\n",
            "    168274 (1.10%) aligned 0 times\n",
            "    13320505 (87.38%) aligned exactly 1 time\n",
            "    1755932 (11.52%) aligned >1 times\n",
            "98.90% overall alignment rate\n"
          ]
        }
      ],
      "source": [
        "!cat SRR3414630.hisat\n",
        "!rm SRR3414630.hisat\n",
        "!rm SRR3414630_1.fastq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC5H0CMJUrTz"
      },
      "source": [
        "## SRR3414631:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOnUHKsyU-HI",
        "outputId": "3bbb04e6-ceee-4eb7-fc01-5551c8b16f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t18m7.731s\n",
            "user\t26m43.959s\n",
            "sys\t1m58.104s\n",
            "removed 'SRR3414631_1.sam'\n",
            "21159606\n"
          ]
        }
      ],
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414631_1.fastq -S SRR3414631_1.sam  2>  SRR3414631.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414631_1.sam > SRR3414631.uniq.sam\n",
        "!rm -v SRR3414631_1.sam\n",
        "!grep -v '^@' SRR3414631.uniq.sam | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94LCvZ5aU-oe",
        "outputId": "abee44e9-1361-4587-a1b4-1864e44104fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24244069 reads; of these:\n",
            "  24244069 (100.00%) were unpaired; of these:\n",
            "    279694 (1.15%) aligned 0 times\n",
            "    21159606 (87.28%) aligned exactly 1 time\n",
            "    2804769 (11.57%) aligned >1 times\n",
            "98.85% overall alignment rate\n"
          ]
        }
      ],
      "source": [
        "!cat SRR3414631.hisat\n",
        "!rm SRR3414631.hisat\n",
        "!rm SRR3414631_1.fastq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdRSNiSCUu6p"
      },
      "source": [
        "## SRR3414635:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRbwYoSYVBGj",
        "outputId": "934d9ea8-3363-4eac-f6c6-c66ef77edfb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t15m7.340s\n",
            "user\t22m10.034s\n",
            "sys\t1m39.660s\n",
            "removed 'SRR3414635_1.sam'\n",
            "18637053\n"
          ]
        }
      ],
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414635_1.fastq -S SRR3414635_1.sam  2>  SRR3414635.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414635_1.sam > SRR3414635.uniq.sam\n",
        "!rm -v SRR3414635_1.sam\n",
        "!grep -v '^@' SRR3414635.uniq.sam | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1psHvXTVCUK",
        "outputId": "980ab8c2-77c4-416a-cc72-cf9ae73126a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20956475 reads; of these:\n",
            "  20956475 (100.00%) were unpaired; of these:\n",
            "    242044 (1.15%) aligned 0 times\n",
            "    18637053 (88.93%) aligned exactly 1 time\n",
            "    2077378 (9.91%) aligned >1 times\n",
            "98.85% overall alignment rate\n"
          ]
        }
      ],
      "source": [
        "!cat SRR3414635.hisat\n",
        "!rm SRR3414635.hisat\n",
        "!rm SRR3414635_1.fastq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzjvzd1XUzee"
      },
      "source": [
        "## SRR3414636:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DORlkP0GVDo5",
        "outputId": "fe1b219d-0e31-490f-b86b-92de5e131fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t14m41.452s\n",
            "user\t21m35.023s\n",
            "sys\t1m38.047s\n",
            "removed 'SRR3414636_1.sam'\n",
            "18032679\n"
          ]
        }
      ],
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414636_1.fastq -S SRR3414636_1.sam  2>  SRR3414636.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414636_1.sam > SRR3414636.uniq.sam\n",
        "!rm -v SRR3414636_1.sam\n",
        "!grep -v '^@' SRR3414636.uniq.sam | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL8MXyV1VEwh",
        "outputId": "ed698784-ced1-41a8-db24-ded2e1bcb331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20307147 reads; of these:\n",
            "  20307147 (100.00%) were unpaired; of these:\n",
            "    233551 (1.15%) aligned 0 times\n",
            "    18032679 (88.80%) aligned exactly 1 time\n",
            "    2040917 (10.05%) aligned >1 times\n",
            "98.85% overall alignment rate\n"
          ]
        }
      ],
      "source": [
        "!cat SRR3414636.hisat\n",
        "!rm SRR3414636.hisat\n",
        "!rm SRR3414636_1.fastq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI6nlqH9U1x4"
      },
      "source": [
        "## SRR3414637:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICvf9zopVGBH",
        "outputId": "b702f980-1d84-40ce-84d0-ce8b7091cd3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t14m43.259s\n",
            "user\t21m38.286s\n",
            "sys\t1m37.749s\n",
            "removed 'SRR3414637_1.sam'\n",
            "18043406\n"
          ]
        }
      ],
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414637_1.fastq -S SRR3414637_1.sam  2>  SRR3414637.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414637_1.sam > SRR3414637.uniq.sam\n",
        "!rm -v SRR3414637_1.sam\n",
        "!grep -v '^@' SRR3414637.uniq.sam | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHSaxjUkUn_R",
        "outputId": "40d1c36d-9c0e-4f7f-fb79-5a8635377f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20385570 reads; of these:\n",
            "  20385570 (100.00%) were unpaired; of these:\n",
            "    236895 (1.16%) aligned 0 times\n",
            "    18043406 (88.51%) aligned exactly 1 time\n",
            "    2105269 (10.33%) aligned >1 times\n",
            "98.84% overall alignment rate\n"
          ]
        }
      ],
      "source": [
        "!cat SRR3414637.hisat\n",
        "!rm SRR3414637.hisat\n",
        "!rm SRR3414637_1.fastq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jhS7w1EVSs9"
      },
      "source": [
        "## Теперь через HTSeq подсчитываем количество чтений, попавших на каждый ген"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnzYfuEnVaz9",
        "outputId": "d33f815a-9158-4413-b8e4-f0552bfb480d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18500000 alignment records processed.\n",
            "18573565 alignment records processed.\n",
            "\n",
            "real\t23m50.164s\n",
            "user\t23m20.631s\n",
            "sys\t0m9.567s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13320505 alignment records processed.\n",
            "\n",
            "real\t17m32.939s\n",
            "user\t17m10.347s\n",
            "sys\t0m7.391s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18500000 alignment records processed.\n",
            "18600000 alignment records processed.\n",
            "18700000 alignment records processed.\n",
            "18800000 alignment records processed.\n",
            "18900000 alignment records processed.\n",
            "19000000 alignment records processed.\n",
            "19100000 alignment records processed.\n",
            "19200000 alignment records processed.\n",
            "19300000 alignment records processed.\n",
            "19400000 alignment records processed.\n",
            "19500000 alignment records processed.\n",
            "19600000 alignment records processed.\n",
            "19700000 alignment records processed.\n",
            "19800000 alignment records processed.\n",
            "19900000 alignment records processed.\n",
            "20000000 alignment records processed.\n",
            "20100000 alignment records processed.\n",
            "20200000 alignment records processed.\n",
            "20300000 alignment records processed.\n",
            "20400000 alignment records processed.\n",
            "20500000 alignment records processed.\n",
            "20600000 alignment records processed.\n",
            "20700000 alignment records processed.\n",
            "20800000 alignment records processed.\n",
            "20900000 alignment records processed.\n",
            "21000000 alignment records processed.\n",
            "21100000 alignment records processed.\n",
            "21159606 alignment records processed.\n",
            "\n",
            "real\t26m11.050s\n",
            "user\t25m40.018s\n",
            "sys\t0m10.588s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18500000 alignment records processed.\n",
            "18600000 alignment records processed.\n",
            "18637053 alignment records processed.\n",
            "\n",
            "real\t23m36.543s\n",
            "user\t23m10.446s\n",
            "sys\t0m9.171s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18032679 alignment records processed.\n",
            "\n",
            "real\t23m1.776s\n",
            "user\t22m35.178s\n",
            "sys\t0m10.033s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18043406 alignment records processed.\n",
            "\n",
            "real\t22m44.469s\n",
            "user\t22m16.930s\n",
            "sys\t0m11.265s\n"
          ]
        }
      ],
      "source": [
        "!time htseq-count --format=sam --stranded=no SRR3414629.uniq.sam  gencode.vM25.annotation.gtf > SRR3414629.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414630.uniq.sam  gencode.vM25.annotation.gtf > SRR3414630.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414631.uniq.sam  gencode.vM25.annotation.gtf > SRR3414631.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414635.uniq.sam  gencode.vM25.annotation.gtf > SRR3414635.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414636.uniq.sam  gencode.vM25.annotation.gtf > SRR3414636.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414637.uniq.sam  gencode.vM25.annotation.gtf > SRR3414637.counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ee8e1yeVDE2"
      },
      "source": [
        "## Ура, после двух часов мук давайте посмотрим, сколько чтений не удалось приписать ни одному гену"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHTMa6RlA_m4"
      },
      "source": [
        "* `__no_feature ` – столько чтений соответствует участкам генома, где не аннотировано ни одного экзона\n",
        "* `__ambiguous ` – столько чтений могут принадлежать разным генам\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnIbXFRqVP3o",
        "outputId": "394e3a4a-a924-48e0-ac94-3853b6dbc7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1620359\n",
            "__ambiguous\t728893\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ],
      "source": [
        "! grep '^__' SRR3414629.counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H0K3V9WVRdQ",
        "outputId": "a38fbecf-14cb-4188-b694-96c90ba32c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1251763\n",
            "__ambiguous\t484967\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ],
      "source": [
        "! grep '^__' SRR3414630.counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp6-WLyBVSzQ",
        "outputId": "669d49f6-1d59-4b41-f913-f2c9a29e3483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1718354\n",
            "__ambiguous\t827751\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ],
      "source": [
        "! grep '^__' SRR3414631.counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty4ZU0oFVUUg",
        "outputId": "64783884-2742-4bf9-949d-c8dc2c282512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1406679\n",
            "__ambiguous\t767361\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ],
      "source": [
        "! grep '^__' SRR3414635.counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IkF1feXVWa0",
        "outputId": "d88c672d-728d-46ad-a1d1-7d18934f87ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1347210\n",
            "__ambiguous\t742802\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ],
      "source": [
        "! grep '^__' SRR3414636.counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZzXz1CkVZs8",
        "outputId": "0d1d0870-a6b1-4023-d6c9-263a84d662af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1411488\n",
            "__ambiguous\t717538\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ],
      "source": [
        "! grep '^__' SRR3414637.counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ-ryqO0BiDp"
      },
      "source": [
        "* Объединям все файлы .counts по генам в один общий файл `ALL.counts`.\n",
        "* В качестве заголовка для каждого образца указывать не его SRR id, а c1, c2, c3 для контрольных образцов и r1, r2, r3 для перепрограммированных образцов.\n",
        "* Загружаем полученный ALL.counts файл в Github репозиторий"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## А также выведем общее количество чтений для каждой последовательности"
      ],
      "metadata": {
        "id": "K-OjwHJrsqek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"SRR3414629: {18573565 - 1620359 - 728893 = }\")\n",
        "print(f\"SRR3414630: {13320505 - 1251763 - 484967 = }\")\n",
        "print(f\"SRR3414631: {21159606 - 1718354 - 827751 = }\")\n",
        "print(f\"SRR3414635: {18637053 - 1406679 - 767361 = }\")\n",
        "print(f\"SRR3414636: {18032679 - 1347210 - 742802 = }\")\n",
        "print(f\"SRR3414637: {18043406 - 1411488 - 717538 = }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXHzxeeMswwu",
        "outputId": "d7d64d82-dc61-41e1-9001-9478d7126d21"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRR3414629: 18573565 - 1620359 - 728893 = 16224313\n",
            "SRR3414630: 13320505 - 1251763 - 484967 = 11583775\n",
            "SRR3414631: 21159606 - 1718354 - 827751 = 18613501\n",
            "SRR3414635: 18637053 - 1406679 - 767361 = 16463013\n",
            "SRR3414636: 18032679 - 1347210 - 742802 = 15942667\n",
            "SRR3414637: 18043406 - 1411488 - 717538 = 15914380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6nv1mCCkUYn"
      },
      "source": [
        " ## Теперь объединяем все файлы .counts по генам в один общий файл ALL.counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-oI9Qq0mVvhp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_prefixes = ['SRR3414635', 'SRR3414636', 'SRR3414637', 'SRR3414629', 'SRR3414630', 'SRR3414631']\n",
        "column_names = ['geneID', 'c1', 'c2', 'c3', 'r1', 'r2', 'r3']\n",
        "\n",
        "dfs = [pd.read_csv(f'{prefix}.counts', sep=\"\\t\", names=['geneID', prefix]) for prefix in file_prefixes]\n",
        "merged_df = pd.concat(dfs, axis=1)\n",
        "\n",
        "all_counts = merged_df[:-5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFiPJjsP9KW7"
      },
      "source": [
        "Ура! Качаем `ALL.counts`.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cNsBpjKP5vh3",
        "outputId": "985bb7a0-9e6b-44f4-8e74-7d7a29e0af4b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a07f6987-c4d0-4d7b-bd63-948e25d16042\", \"ALL.counts\", 8213258)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "all_counts.to_csv('ALL.counts')\n",
        "files.download('ALL.counts')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}